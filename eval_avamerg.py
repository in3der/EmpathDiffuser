import os
import json
import torch
import numpy as np
from tqdm import tqdm
from torchvision.utils import save_image
from torch.utils.data import DataLoader
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from torchvision import transforms
from PIL import Image
from sample_multi_v1 import evaluate
from libs.caption_decoder import CaptionDecoder
import importlib.util
from absl import flags
from absl import app
from ml_collections import config_flags
import os
import time

# ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹
class AvaMERGDataset(torch.utils.data.Dataset):
    def __init__(self, json_path, image_root):
        with open(json_path, 'r') as f:
            self.data = json.load(f)
        self.image_root = image_root
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((256, 256))
        ])

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        input_image = self.transform(Image.open(os.path.join(self.image_root, item['input_image'])).convert('RGB'))
        output_image = self.transform(Image.open(os.path.join(self.image_root, item['output_image'])).convert('RGB'))
        return {
            'input_image': input_image,
            'input_text': item['input_text'],
            'output_image': output_image,
            'output_text': item['output_text']
        }

# BLEU ê³„ì‚° í•¨ìˆ˜
bleu_smoother = SmoothingFunction().method4
def compute_bleu(reference, hypothesis):
    return sentence_bleu([reference.split()], hypothesis.split(), smoothing_function=bleu_smoother)

# FID ê³„ì‚° í•¨ìˆ˜ êµ¬í˜„ (clean-fid ë˜ëŠ” pytorch-fid í•„ìš”)
def calculate_fid_given_paths(paths, batch_size=32, device='cuda', dims=2048):
    try:
        from cleanfid import fid
        return fid.compute_fid(paths[0], paths[1], batch_size=batch_size, device=device, mode="clean")
    except ImportError:
        print("[!] clean-fidê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install clean-fid")
        return float('nan')

# ë©”ì¸ í‰ê°€ ë£¨í”„
def evaluate_model(config, json_path, image_root, output_dir, batch_size=4):
    dataset = AvaMERGDataset(json_path, image_root)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'pred_images'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'gt_images'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'text_pairs'), exist_ok=True)

    all_bleu = []
    pred_image_paths, gt_image_paths = [], []

    for i, batch in enumerate(tqdm(dataloader)):
        for j in range(batch_size):
            idx = i * batch_size + j
            config.mode = 'joint'
            config.n_samples = 1
            config.prompt = batch['input_text'][j]
            config.seed = int(time.time()) + idx  # â† ëœë¤ì„± ë¶€ì—¬ (ì¤‘ë³µ ë°©ì§€)

            evaluate(config)

            preds_path = os.path.join(config.output_path, 'joint')
            pred_img = Image.open(os.path.join(preds_path, '0.png')).convert('RGB')
            pred_img_path = os.path.join(output_dir, 'pred_images', f'{idx}.png')
            pred_img.save(pred_img_path)
            pred_image_paths.append(pred_img_path)

            gt_img = batch['output_image'][j]
            gt_img_path = os.path.join(output_dir, 'gt_images', f'{idx}.png')
            save_image(gt_img, gt_img_path)
            gt_image_paths.append(gt_img_path)

            with open(os.path.join(preds_path, 'prompts.txt'), 'r') as f:
                generated_text = f.readline().strip()

            input_text = batch['input_text'][j]
            output_text = batch['output_text'][j]
            text_pair_path = os.path.join(output_dir, 'text_pairs', f'{idx}.txt')
            with open(text_pair_path, 'w') as tf:
                tf.write(f"[INPUT] {input_text}\n")
                tf.write(f"[TARGET] {output_text}\n")
                tf.write(f"[GENERATED] {generated_text}\n")

            bleu = compute_bleu(output_text, generated_text)
            all_bleu.append(bleu)
            print(f"[INPUT] {input_text}\n")
            print(f"[TARGET] {output_text}\n")
            print(f"[GENERATED] {generated_text}\n")
            print(f"[Sample {idx}] BLEU: {bleu:.6f}")

        # ì¤‘ê°„ FID ê³„ì‚°
        if len(pred_image_paths) >= batch_size:
            fid = calculate_fid_given_paths([os.path.join(output_dir, 'gt_images'),
                                             os.path.join(output_dir, 'pred_images')],
                                            batch_size=32, device='cuda', dims=2048)
            print(f"[Batch {i}] Current FID: {fid:.6f}")

    # ìµœì¢… FID ê³„ì‚° ë° ì €ì¥
    fid = calculate_fid_given_paths([os.path.join(output_dir, 'gt_images'),
                                     os.path.join(output_dir, 'pred_images')],
                                     batch_size=32, device='cuda', dims=2048)

    results = {
        'BLEU': float(np.mean(all_bleu)),
        'FID': float(fid)
    }
    with open(os.path.join(output_dir, 'metrics.json'), 'w') as f:
        json.dump(results, f, indent=4)

    print("\nğŸ“Š Evaluation Complete")
    print(f"Average BLEU: {results['BLEU']:.6f}")
    print(f"FID: {results['FID']:.6f}")

def load_config_from_py(path):
    spec = importlib.util.spec_from_file_location("config_module", path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module.get_config()

FLAGS = flags.FLAGS

# í•„ìš”í•œ flagsë§Œ ì •ì˜ (ì¤‘ë³µ ì²´í¬)
def define_flag_if_not_exists(flag_type, name, default, help_text):
    try:
        if flag_type == 'string':
            flags.DEFINE_string(name, default, help_text)
        elif flag_type == 'integer':
            flags.DEFINE_integer(name, default, help_text)
    except flags._exceptions.DuplicateFlagError:
        pass  # ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆìœ¼ë©´ ë¬´ì‹œ


# í•„ìš”í•œ flags ì •ì˜
define_flag_if_not_exists('string', "nnet_path",
                          "/home/ivpl-d29/sichoi/Emo/unidiffuser/si_finetuning_2/leg_checkpoint_step_4000.pth",
                          "The nnet to evaluate.")
define_flag_if_not_exists('string', "output_path", "out", "dir to write results to")
define_flag_if_not_exists('string', "prompt", "an elephant under the sea",
                          "the prompt for text-to-image generation and text variation")
define_flag_if_not_exists('string', "img", "assets/space.jpg",
                          "the image path for image-to-text generation and image variation")
define_flag_if_not_exists('integer', "n_samples", 1, "the number of samples to generate")
define_flag_if_not_exists('integer', "nrow", 4, "number of images displayed in each row of the grid")
define_flag_if_not_exists('string', "mode", None, "type of generation, one of t2i / i2t / joint / i / t / i2t2i/ t2i2t")


def main(argv):
    # config íŒŒì¼ì—ì„œ ê¸°ë³¸ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
    config_path = 'configs/sample_unidiffuser_v1.py'
    config = load_config_from_py(config_path)

    # FLAGSë¡œë¶€í„° ì¶”ê°€ ì„¤ì • ì—…ë°ì´íŠ¸
    config.nnet_path = FLAGS.nnet_path
    config.output_path = FLAGS.output_path
    config.prompt = FLAGS.prompt
    config.nrow = min(FLAGS.nrow, FLAGS.n_samples)
    config.img = FLAGS.img
    config.n_samples = FLAGS.n_samples
    config.mode = FLAGS.mode

    # ì¶”ê°€ ì„¤ì •
    json_path = "/home/ivpl-d29/dataset/AvaMERG/test_finetune.json"
    image_root = "/home/ivpl-d29/dataset/AvaMERG/image_v5_0/"
    output_dir = "eval_output"
    batch_size = 4

    evaluate_model(config, json_path, image_root, output_dir, batch_size)


if __name__ == '__main__':
    app.run(main)